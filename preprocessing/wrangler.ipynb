{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing of the Log File\n",
    "#### We will preprocessing and wrangle the messy log files and cleanly populate the dataframe. This dataframe will be used to visualise our data in our web app using Dash Plotly framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read contents of the file to the program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"error.txt\", \"r\")\n",
    "contents = \"\"\n",
    "for i in range(5000):\n",
    "    contents += str(file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split contents of file with respect to newline to make strings \n",
    "lines = contents.split('\\n') # list of log entries\n",
    "\n",
    "date_time_list = []\n",
    "severity_level_list = []\n",
    "dirty_list = []\n",
    "for line in lines:\n",
    "    pieces = line.split(\" \")\n",
    "    if len(pieces) > 11: # some lines are less than the minimum required length\n",
    "        date_time_list.append(\" \".join([pieces[dt] for dt in range(5)]))\n",
    "        severity_level_list.append(pieces[5])\n",
    "        dirty_list.append(\" \".join([pieces[e] for e in range(6,len(pieces),1)]))\n",
    "\n",
    "# clean the error messages\n",
    "error_msg_list = []\n",
    "error_msg = \"\"\n",
    "for dirty in dirty_list:\n",
    "    dirty_pieces = dirty.split(\" \")\n",
    "    error_msg = \"\"\n",
    "    for dirt_piece in dirty_pieces:\n",
    "        if not any(char.isdigit() for char in dirt_piece):\n",
    "            if not any(not char.isalnum() for char in dirt_piece):\n",
    "                error_msg += dirt_piece + \" \"\n",
    "    error_msg = \" \".join(error_msg.split(\" \")[:5])\n",
    "    if error_msg:\n",
    "        error_msg_list.append(error_msg.lower())\n",
    "    \n",
    "# clean and formate the dates\n",
    "MONTH_MAP = {\n",
    "    # map words to their digits representations\n",
    "    \"Jan\":\"01\",\"Feb\":\"02\",\"Mar\":\"03\",\"Apr\":\"04\",\"May\":\"05\",\"Jun\":\"06\",\n",
    "    \"Jul\":\"07\",\"Aug\":\"08\",\"Sep\":\"09\",\"Oct\":\"10\",\"Nov\":\"11\",\"Dec\":\"12\"\n",
    "}\n",
    "day_of_week_list = []\n",
    "date_list = []\n",
    "for date_time_str in date_time_list:\n",
    "    date_time_str = date_time_str.replace('[','')\n",
    "    date_time_str = date_time_str.replace(']','')\n",
    "    date_time_pieces = date_time_str.split(\" \")\n",
    "    day_of_week_list.append(date_time_pieces[0])\n",
    "    formatted_date_str = date_time_pieces[2] +\"/\"+ MONTH_MAP[date_time_pieces[1][:3]] +\"/\"+ date_time_pieces[4][2:]\n",
    "    # convert date string to actual date object and append to date list\n",
    "    date_list.append(datetime.strptime(formatted_date_str, '%d/%m/%y').date())\n",
    "\n",
    "'''\n",
    "# remove error_messages that are too damn long\n",
    "for e in error_msg_list:\n",
    "    e = re.sub(' +', ' ', e) # removes double whitespaces\n",
    "    if not len(e.split(\" \")) > 5:\n",
    "        e = e.join(\" \")\n",
    "        if e in error_msg_list:\n",
    "            index = error_msg_list.index(e)\n",
    "            error_msg_list.pop(index)\n",
    "            date_list.pop(index)\n",
    "            day_of_week_list.pop(index)\n",
    "            severity_level_list.pop(index)\n",
    "'''\n",
    "\n",
    "# create the dictionary of all the wrangled log file data\n",
    "data = {\n",
    "    \"date\": date_list,\n",
    "    \"day_of_the_week\": day_of_week_list,\n",
    "    \"severity_level\": severity_level_list,\n",
    "    \"error_messages\": error_msg_list\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting insight for Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>day_of_the_week</th>\n",
       "      <th>error_messages</th>\n",
       "      <th>severity_level</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>cannot serve directory no matching</td>\n",
       "      <td>[autoindex:error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>cannot serve directory no matching</td>\n",
       "      <td>[autoindex:error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>cannot serve directory no matching</td>\n",
       "      <td>[autoindex:error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>cannot serve directory no matching</td>\n",
       "      <td>[autoindex:error]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>Mon</td>\n",
       "      <td>cannot serve directory no matching</td>\n",
       "      <td>[autoindex:error]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date day_of_the_week                      error_messages  \\\n",
       "0  2018-02-12             Mon  cannot serve directory no matching   \n",
       "1  2018-02-12             Mon  cannot serve directory no matching   \n",
       "2  2018-02-12             Mon  cannot serve directory no matching   \n",
       "3  2018-02-12             Mon  cannot serve directory no matching   \n",
       "4  2018-02-12             Mon  cannot serve directory no matching   \n",
       "\n",
       "      severity_level  \n",
       "0  [autoindex:error]  \n",
       "1  [autoindex:error]  \n",
       "2  [autoindex:error]  \n",
       "3  [autoindex:error]  \n",
       "4  [autoindex:error]  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the dataframe\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count how frequently each error messages occurs \n",
    "unique_errors_counts = df['error_messages'].value_counts()\n",
    "unique_error_frequencies = {\n",
    "    \"unique_error_msgs\": list(unique_errors_counts.index.values),\n",
    "    \"frequencies\": unique_errors_counts.tolist()\n",
    "}\n",
    "#unique_error_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108, 291, 4601]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2018, 2019, 2020]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count how frequently each error occurs per month\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "#df = df.set_index('date')\n",
    "#dg = df.groupby(pd.Grouper(key='date', freq='1M')).sum()\n",
    "#dg\n",
    "#dg.index = dg.index.strftime('%B')\n",
    "#dg\n",
    "#df['error_messages'].resample('M').sum()\n",
    "#gd = df.groupby('date').count()\n",
    "gy = df.groupby(pd.Grouper(key='date', freq='Y'))['error_messages'].count().tolist()\n",
    "print(gy)\n",
    "df['Year'] = pd.DatetimeIndex(df['date']).year\n",
    "df['Year'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit3c684b9b280e460683b25251b1d816f1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
